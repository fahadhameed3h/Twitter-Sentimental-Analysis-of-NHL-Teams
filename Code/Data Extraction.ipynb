{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Names of National Hockey League Teams\n",
    "Retreiving National Hockey League(NHL) 32 teams names using BeauitfulSoap and storing names into pandas dataframe \"NHLTeams_DF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name\n",
      "0           Boston Bruins\n",
      "1          Buffalo Sabres\n",
      "2       Detroit Red Wings\n",
      "3        Florida Panthers\n",
      "4      Montreal Canadiens\n",
      "5         Ottawa Senators\n",
      "6     Tampa Bay Lightning\n",
      "7     Toronto Maple Leafs\n",
      "8      Chicago Blackhawks\n",
      "9      Colorado Avalanche\n",
      "10           Dallas Stars\n",
      "11         Minnesota Wild\n",
      "12    Nashville Predators\n",
      "13        St. Louis Blues\n",
      "14          Winnipeg Jets\n",
      "15    Carolina Hurricanes\n",
      "16  Columbus Blue Jackets\n",
      "17      New Jersey Devils\n",
      "18     New York Islanders\n",
      "19       New York Rangers\n",
      "20    Philadelphia Flyers\n",
      "21    Pittsburgh Penguins\n",
      "22    Washington Capitals\n",
      "23          Anaheim Ducks\n",
      "24        Arizona Coyotes\n",
      "25         Calgary Flames\n",
      "26        Edmonton Oilers\n",
      "27      Los Angeles Kings\n",
      "28        San Jose Sharks\n",
      "29      Vancouver Canucks\n",
      "30   Vegas Golden Knights\n"
     ]
    }
   ],
   "source": [
    "url_player = \"http://www.espn.com/nhl/teams\"\n",
    "players = requests.get(url_player)\n",
    "soup = BeautifulSoup(players.text, \"lxml\")\n",
    "\n",
    "new_soup = soup.find(\"div\", {\"class\":\"layout is-split\"} )\n",
    "teams = list()\n",
    "\n",
    "for div in new_soup.findAll('h2', {'class': 'clr-gray-01 di h5'}):\n",
    "    teams.append(div.text)\n",
    "\n",
    "NHLTeams_DF = pd.DataFrame({'Name':teams})\n",
    "NHLTeams_DF.to_csv(\"NHL_Teams\",index=False)\n",
    "print(NHLTeams_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting with Twitter REST Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= '************************************'\n",
    "consumer_secret= '************************************'\n",
    "\n",
    "access_token='************************************'\n",
    "access_token_secret='************************************'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "AllTweets = list()\n",
    "prTweets = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Tweets with hastag of team names\n",
    "Getting Tweets of NHL teams with hashtag of team names including Author name and date of tweets. Storing all tweets in seperate csv file.\n",
    "Getting tweets seperately for each team to get more and specific results for each team.\n",
    "\n",
    "Storing data in seperate files with names of team_name.csv. Getting 500 tweets for each team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Boston_Bruins.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Boston Bruins\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Buffalo_Sabres.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Buffalo Sabres\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Detroit_Red_Wings.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Detroit Red Wings\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Florida_Panthers.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Florida Panthers\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Montreal_Canadiens.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Montreal Canadiens\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Ottawa_Senators.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Ottawa_Senators\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Tampa_Bay_Lightning.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Tampa Bay Lightning\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Toronto_Maple_Leafs.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Toronto Maple Leafs\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Chicago_Blackhawks.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Chicago Blackhawks\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Colorado_Avalanche.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Colorado Avalanche\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dallas_Stars.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Dallas Stars\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Minnesota_Wild.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Minnesota_Wild\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Nashville_Predators.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Nashville Predators\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('St._Louis_Blues.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"St. Louis Blues\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Winnipeg_Jets.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Winnipeg Jets\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Carolina_Hurricanes.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Carolina Hurricanes\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Columbus_Blue_Jackets.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Columbus Blue Jackets\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('New_Jersey_Devils.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"New Jersey Devils\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('New_York_Islanders.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"New York Islanders\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('New_York_Rangers.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"New York Rangers\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Philadelphia_Flyers.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Philadelphia Flyers\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Pittsburgh_Penguins.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Pittsburgh Penguins\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Washington_Capitals.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Washington Capitals\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Anaheim_Ducks.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Anaheim Ducks\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Arizona_Coyotes.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Arizona Coyotes\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Calgary_Flames.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Calgary Flames\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Edmonton_Oilers.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Edmonton Oilers\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Los_Angeles_Kings.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Los Angeles Kings\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('San_Jose_Sharks.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"San Jose Sharks\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Vancouver_Canucks.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Vancouver Canucks\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Vegas_Golden_Knights.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    tweets = tweepy.Cursor(api.search, q=\"Vegas_Golden_Knights\" ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "    for tweet in tweets:        \n",
    "        tweet_text = tweet.full_text\n",
    "        tweet_user = tweet.user.name\n",
    "        tweet_created_at = tweet.created_at\n",
    "        tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of Tweets dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets and columns:  (500, 3)\n"
     ]
    }
   ],
   "source": [
    "Boston_Bruins_tweets = pd.read_csv(\"Boston_Bruins.csv\")\n",
    "print(\"Number of Tweets and columns: \",Boston_Bruins_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bruins notebook: Danton Heinen getting the job...</td>\n",
       "      <td>The Gardner News</td>\n",
       "      <td>2019-03-01 01:11:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tampa Bay Lightning at Boston Bruins: Streak v...</td>\n",
       "      <td>Lightnings Fans</td>\n",
       "      <td>2019-03-01 01:10:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of the players at the Bruins vs. Tampa gam...</td>\n",
       "      <td>Elizabeth Ellen</td>\n",
       "      <td>2019-03-01 01:10:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @BezansonAlex: HUG FOUNDATION OF MA INC is ...</td>\n",
       "      <td>paul fitzgerald</td>\n",
       "      <td>2019-03-01 01:10:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @SavageBoston: ARE YOU ALL IN ON THE BOSTON...</td>\n",
       "      <td>Gun Bun</td>\n",
       "      <td>2019-03-01 01:09:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet            Author  \\\n",
       "0  Bruins notebook: Danton Heinen getting the job...  The Gardner News   \n",
       "1  Tampa Bay Lightning at Boston Bruins: Streak v...   Lightnings Fans   \n",
       "2  One of the players at the Bruins vs. Tampa gam...   Elizabeth Ellen   \n",
       "3  RT @BezansonAlex: HUG FOUNDATION OF MA INC is ...   paul fitzgerald   \n",
       "4  RT @SavageBoston: ARE YOU ALL IN ON THE BOSTON...           Gun Bun   \n",
       "\n",
       "                  Date  \n",
       "0  2019-03-01 01:11:46  \n",
       "1  2019-03-01 01:10:56  \n",
       "2  2019-03-01 01:10:13  \n",
       "3  2019-03-01 01:10:09  \n",
       "4  2019-03-01 01:09:21  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boston_Bruins_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Tweets with hastag of team names together at once\n",
    "Getting Tweets of NHL teams with hastag of team names including Author name and date of tweets. Storing all tweets in csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TeamsTwittes_V1.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    for hastag in teams:\n",
    "        tweets = tweepy.Cursor(api.search, q= hastag ,lang = \"en\",tweet_mode = 'extended').items(300)\n",
    "        for tweet in tweets:        \n",
    "            tweet_text = tweet.full_text\n",
    "            tweet_user = tweet.user.name\n",
    "            tweet_created_at = tweet.created_at\n",
    "            tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTeamTweets_OnceCollected = pd.read_csv(\"TeamsTweets_V1.csv\")  # tweets to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets and columns:  (2668, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Tweets and columns: \",AllTeamTweets_OnceCollected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston bruins finally won this one. Celtics an...</td>\n",
       "      <td>Dorothy Brenner</td>\n",
       "      <td>2019-01-18 10:12:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York Rangers vs Boston Bruins, Jan 19, 201...</td>\n",
       "      <td>borshchenko</td>\n",
       "      <td>2019-01-18 09:56:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @BostonDotCom: 4 takeaways from the Bruins’...</td>\n",
       "      <td>Diane D</td>\n",
       "      <td>2019-01-18 09:20:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @hockeyfights: Patrick Maroon vs Zdeno Char...</td>\n",
       "      <td>Tommy McInerney</td>\n",
       "      <td>2019-01-18 08:28:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @hockeyfights: Patrick Maroon vs Zdeno Char...</td>\n",
       "      <td>Vitaly Litvinov</td>\n",
       "      <td>2019-01-18 08:18:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet           Author  \\\n",
       "0  Boston bruins finally won this one. Celtics an...  Dorothy Brenner   \n",
       "1  New York Rangers vs Boston Bruins, Jan 19, 201...      borshchenko   \n",
       "2  RT @BostonDotCom: 4 takeaways from the Bruins’...          Diane D   \n",
       "3  RT @hockeyfights: Patrick Maroon vs Zdeno Char...  Tommy McInerney   \n",
       "4  RT @hockeyfights: Patrick Maroon vs Zdeno Char...  Vitaly Litvinov   \n",
       "\n",
       "                  Date  \n",
       "0  2019-01-18 10:12:42  \n",
       "1  2019-01-18 09:56:37  \n",
       "2  2019-01-18 09:20:15  \n",
       "3  2019-01-18 08:28:55  \n",
       "4  2019-01-18 08:18:29  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllTeamTweets_OnceCollected[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Files for tweets of all teams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boston_Bruins = pd.read_csv(\"Boston_Bruins.csv\") \n",
    "Buffalo_Sabres = pd.read_csv(\"Buffalo_Sabres.csv\")  \n",
    "Detroit_Red_Wings = pd.read_csv(\"Detroit_Red_Wings.csv\") \n",
    "Florida_Panthers = pd.read_csv(\"Florida_Panthers.csv\") \n",
    "Montreal_Canadiens = pd.read_csv(\"Montreal_Canadiens.csv\")\n",
    "Ottawa_Senators = pd.read_csv(\"Ottawa_Senators.csv\")\n",
    "Tampa_Bay_Lightning = pd.read_csv(\"Tampa_Bay_Lightning.csv\")\n",
    "Toronto_Maple_Leafs = pd.read_csv(\"Toronto_Maple_Leafs.csv\")\n",
    "Chicago_Blackhawks = pd.read_csv(\"Chicago_Blackhawks.csv\")\n",
    "Colorado_Avalanche = pd.read_csv(\"Colorado_Avalanche.csv\")\n",
    "Dallas_Stars = pd.read_csv(\"Dallas_Stars.csv\")\n",
    "Minnesota_Wild = pd.read_csv(\"Minnesota_Wild.csv\")\n",
    "Nashville_Predators = pd.read_csv(\"Nashville_Predators.csv\")\n",
    "St_Louis_Blues = pd.read_csv(\"St._Louis_Blues.csv\")\n",
    "Winnipeg_Jets = pd.read_csv(\"Winnipeg_Jets.csv\")\n",
    "Carolina_Hurricanes = pd.read_csv(\"Carolina_Hurricanes.csv\")\n",
    "Columbus_Blue_Jackets = pd.read_csv(\"Columbus_Blue_Jackets.csv\")\n",
    "New_Jersey_Devils = pd.read_csv(\"New_Jersey_Devils.csv\")\n",
    "New_York_Islanders = pd.read_csv(\"New_York_Islanders.csv\")\n",
    "New_Jersey_Devils = pd.read_csv(\"New_Jersey_Devils.csv\")\n",
    "New_York_Rangers = pd.read_csv(\"New_York_Rangers.csv\")\n",
    "Philadelphia_Flyers = pd.read_csv(\"Philadelphia_Flyers.csv\")\n",
    "Pittsburgh_Penguins = pd.read_csv(\"Pittsburgh_Penguins.csv\")\n",
    "Washington_Capitals = pd.read_csv(\"Washington_Capitals.csv\")\n",
    "Anaheim_Ducks = pd.read_csv(\"Anaheim_Ducks.csv\")\n",
    "Arizona_Coyotes = pd.read_csv(\"Arizona_Coyotes.csv\")\n",
    "Calgary_Flames = pd.read_csv(\"Calgary_Flames.csv\")\n",
    "Edmonton_Oilers = pd.read_csv(\"Edmonton_Oilers.csv\")\n",
    "Los_Angeles_Kings = pd.read_csv(\"Los_Angeles_Kings.csv\")\n",
    "San_Jose_Sharks = pd.read_csv(\"San_Jose_Sharks.csv\")\n",
    "Vancouver_Canucks = pd.read_csv(\"Vancouver_Canucks.csv\")\n",
    "Vegas_Golden_Knights = pd.read_csv(\"Vegas_Golden_Knights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Tweets datasets of all teams together into one dataset\n",
    "Joining different tweets datasets collected in different files with file names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Teams_Dataset_Names_lst = list([\"Boston_Bruins\", \"Buffalo_Sabres\",\"Detroit_Red_Wings\",\"Florida_Panthers\",\"Montreal_Canadiens\",\n",
    "                            \"Ottawa_Senators\",\"Tampa_Bay_Lightning\",\"Toronto_Maple_Leafs\",\"Chicago_Blackhawks\",\"Colorado_Avalanche\",\n",
    "                            \"Dallas_Stars\",\"Minnesota_Wild\",\"Nashville_Predators\",\"St._Louis_Blues\",\"Winnipeg_Jets\",\"Carolina_Hurricanes\",\n",
    "                            \"Columbus_Blue_Jackets\",\"New_Jersey_Devils\",\"New_York_Islanders\",\"New_York_Rangers\",\"Philadelphia_Flyers\",\n",
    "                            \"Pittsburgh_Penguins\",\"Washington_Capitals\",\"Anaheim_Ducks\",\"Arizona_Coyotes\",\"Calgary_Flames\",\n",
    "                            \"Edmonton_Oilers\",\"Los_Angeles_Kings\",\"San_Jose_Sharks\",\"Vancouver_Canucks\",\"Vegas_Golden_Knights\"])\n",
    "len(All_Teams_Dataset_Names_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinating all the teams datasets into one dataset. 31 teams * 500 tweets each team = 15500, 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets and columns:  (15500, 3)\n"
     ]
    }
   ],
   "source": [
    "AllTeamsTweets = pd.concat([Boston_Bruins, Buffalo_Sabres,Detroit_Red_Wings,Florida_Panthers,Montreal_Canadiens,\n",
    "                            Ottawa_Senators,Tampa_Bay_Lightning,Toronto_Maple_Leafs,Chicago_Blackhawks,Colorado_Avalanche,\n",
    "                            Dallas_Stars,Minnesota_Wild,Nashville_Predators,St_Louis_Blues,Winnipeg_Jets,Carolina_Hurricanes,\n",
    "                            Columbus_Blue_Jackets,New_Jersey_Devils,New_York_Islanders,New_York_Rangers,Philadelphia_Flyers,\n",
    "                            Pittsburgh_Penguins,Washington_Capitals,Anaheim_Ducks,Arizona_Coyotes,Calgary_Flames,\n",
    "                            Edmonton_Oilers,Los_Angeles_Kings,San_Jose_Sharks,Vancouver_Canucks,Vegas_Golden_Knights])\n",
    "print(\"Number of Tweets and columns: \", AllTeamsTweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bruins notebook: Danton Heinen getting the job...</td>\n",
       "      <td>The Gardner News</td>\n",
       "      <td>2019-03-01 01:11:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tampa Bay Lightning at Boston Bruins: Streak v...</td>\n",
       "      <td>Lightnings Fans</td>\n",
       "      <td>2019-03-01 01:10:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of the players at the Bruins vs. Tampa gam...</td>\n",
       "      <td>Elizabeth Ellen</td>\n",
       "      <td>2019-03-01 01:10:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @BezansonAlex: HUG FOUNDATION OF MA INC is ...</td>\n",
       "      <td>paul fitzgerald</td>\n",
       "      <td>2019-03-01 01:10:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @SavageBoston: ARE YOU ALL IN ON THE BOSTON...</td>\n",
       "      <td>Gun Bun</td>\n",
       "      <td>2019-03-01 01:09:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet            Author  \\\n",
       "0  Bruins notebook: Danton Heinen getting the job...  The Gardner News   \n",
       "1  Tampa Bay Lightning at Boston Bruins: Streak v...   Lightnings Fans   \n",
       "2  One of the players at the Bruins vs. Tampa gam...   Elizabeth Ellen   \n",
       "3  RT @BezansonAlex: HUG FOUNDATION OF MA INC is ...   paul fitzgerald   \n",
       "4  RT @SavageBoston: ARE YOU ALL IN ON THE BOSTON...           Gun Bun   \n",
       "\n",
       "                  Date  \n",
       "0  2019-03-01 01:11:46  \n",
       "1  2019-03-01 01:10:56  \n",
       "2  2019-03-01 01:10:13  \n",
       "3  2019-03-01 01:10:09  \n",
       "4  2019-03-01 01:09:21  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllTeamsTweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTeamsTweets.to_csv(\"AllTeamsTweets\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTeamsTweets = pd.read_csv(\"AllTeamsTweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bruins notebook: Danton Heinen getting the job...</td>\n",
       "      <td>The Gardner News</td>\n",
       "      <td>2019-03-01 01:11:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tampa Bay Lightning at Boston Bruins: Streak v...</td>\n",
       "      <td>Lightnings Fans</td>\n",
       "      <td>2019-03-01 01:10:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of the players at the Bruins vs. Tampa gam...</td>\n",
       "      <td>Elizabeth Ellen</td>\n",
       "      <td>2019-03-01 01:10:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @BezansonAlex: HUG FOUNDATION OF MA INC is ...</td>\n",
       "      <td>paul fitzgerald</td>\n",
       "      <td>2019-03-01 01:10:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @SavageBoston: ARE YOU ALL IN ON THE BOSTON...</td>\n",
       "      <td>Gun Bun</td>\n",
       "      <td>2019-03-01 01:09:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet            Author  \\\n",
       "0  Bruins notebook: Danton Heinen getting the job...  The Gardner News   \n",
       "1  Tampa Bay Lightning at Boston Bruins: Streak v...   Lightnings Fans   \n",
       "2  One of the players at the Bruins vs. Tampa gam...   Elizabeth Ellen   \n",
       "3  RT @BezansonAlex: HUG FOUNDATION OF MA INC is ...   paul fitzgerald   \n",
       "4  RT @SavageBoston: ARE YOU ALL IN ON THE BOSTON...           Gun Bun   \n",
       "\n",
       "                  Date  \n",
       "0  2019-03-01 01:11:46  \n",
       "1  2019-03-01 01:10:56  \n",
       "2  2019-03-01 01:10:13  \n",
       "3  2019-03-01 01:10:09  \n",
       "4  2019-03-01 01:09:21  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllTeamsTweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NHL General Trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = [\"NHL\",\"NHL19\",\"NHL2019\",\"National Hockey League\"]\n",
    "with open('NHLTrend.csv', mode='w', encoding=\"utf-8\") as tweets_file:\n",
    "    tweet_writer = csv.writer(tweets_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    tweet_writer.writerow(['Tweet', 'Author', 'Date'])\n",
    "    for hastag in trend:\n",
    "        tweets = tweepy.Cursor(api.search, q= hastag ,lang = \"en\",tweet_mode = 'extended').items(500)\n",
    "        for tweet in tweets:        \n",
    "            tweet_text = tweet.full_text\n",
    "            tweet_user = tweet.user.name\n",
    "            tweet_created_at = tweet.created_at\n",
    "            tweet_writer.writerow([tweet_text, tweet_user, tweet_created_at])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1521, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend = pd.read_csv(\"NHLTrend.csv\")\n",
    "trend.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
